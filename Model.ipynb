{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kelvi\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"sarcasmv3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>comment</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>parent_comment</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_token</th>\n",
       "      <th>parent_comment_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trumpbart</td>\n",
       "      <td>nc and nh</td>\n",
       "      <td>politics</td>\n",
       "      <td>yeah i get that argument at this point i'd pre...</td>\n",
       "      <td>0</td>\n",
       "      <td>[nc, and, nh]</td>\n",
       "      <td>[yeah, i, get, that, argument, at, this, point...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shbshb906</td>\n",
       "      <td>you do know west teams play against west teams...</td>\n",
       "      <td>nba</td>\n",
       "      <td>the blazers and mavericks the wests 5 and 6 se...</td>\n",
       "      <td>0</td>\n",
       "      <td>[you, do, know, west, teams, play, against, we...</td>\n",
       "      <td>[the, blazers, and, mavericks, the, wests, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creepeth</td>\n",
       "      <td>they were underdogs earlier today but since gr...</td>\n",
       "      <td>nfl</td>\n",
       "      <td>they're favored to win</td>\n",
       "      <td>0</td>\n",
       "      <td>[they, were, underdogs, earlier, today, but, s...</td>\n",
       "      <td>[they're, favored, to, win]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>icebrotha</td>\n",
       "      <td>this meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>BlackPeopleTwitter</td>\n",
       "      <td>deadass don't kill my buzz</td>\n",
       "      <td>0</td>\n",
       "      <td>[this, meme, isn't, funny, none, of, the, \", n...</td>\n",
       "      <td>[deadass, don't, kill, my, buzz]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cush2push</td>\n",
       "      <td>i could use one of those tools</td>\n",
       "      <td>MaddenUltimateTeam</td>\n",
       "      <td>yep can confirm i saw the tool they use for th...</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, could, use, one, of, those, tools]</td>\n",
       "      <td>[yep, can, confirm, i, saw, the, tool, they, u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      author                                            comment  \\\n",
       "0  Trumpbart                                         nc and nh    \n",
       "1  Shbshb906  you do know west teams play against west teams...   \n",
       "2   Creepeth  they were underdogs earlier today but since gr...   \n",
       "3  icebrotha  this meme isn't funny none of the \"new york ni...   \n",
       "4  cush2push                    i could use one of those tools    \n",
       "\n",
       "            subreddit                                     parent_comment  \\\n",
       "0            politics  yeah i get that argument at this point i'd pre...   \n",
       "1                 nba  the blazers and mavericks the wests 5 and 6 se...   \n",
       "2                 nfl                            they're favored to win    \n",
       "3  BlackPeopleTwitter                         deadass don't kill my buzz   \n",
       "4  MaddenUltimateTeam  yep can confirm i saw the tool they use for th...   \n",
       "\n",
       "   label                                      comment_token  \\\n",
       "0      0                                      [nc, and, nh]   \n",
       "1      0  [you, do, know, west, teams, play, against, we...   \n",
       "2      0  [they, were, underdogs, earlier, today, but, s...   \n",
       "3      0  [this, meme, isn't, funny, none, of, the, \", n...   \n",
       "4      0             [i, could, use, one, of, those, tools]   \n",
       "\n",
       "                                parent_comment_token  \n",
       "0  [yeah, i, get, that, argument, at, this, point...  \n",
       "1  [the, blazers, and, mavericks, the, wests, 5, ...  \n",
       "2                        [they're, favored, to, win]  \n",
       "3                   [deadass, don't, kill, my, buzz]  \n",
       "4  [yep, can, confirm, i, saw, the, tool, they, u...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def destroy(index):\n",
    "    data.drop(data.index[index], inplace = True)\n",
    "    data.reset_index(drop = True, inplace = True)\n",
    "    all_words = [word for tokens in data[\"comment_token\"] for word in tokens]\n",
    "    sentence_lengths = [len(tokens) for tokens in data[\"comment_token\"]]\n",
    "    VOCAB = sorted(list(set(all_words)))\n",
    "    print(\"%s words total, with a vocabulary size of %s\" % (len(all_words), len(VOCAB)))\n",
    "    print(\"Max sentence length is %s\" % max(sentence_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>comment</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>parent_comment</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_token</th>\n",
       "      <th>parent_comment_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145117</th>\n",
       "      <td>12poulet21</td>\n",
       "      <td>patch notes general gameplay fixed technology ...</td>\n",
       "      <td>gaming</td>\n",
       "      <td>no man's sky has a new update and its huge</td>\n",
       "      <td>0</td>\n",
       "      <td>[patch, notes, general, gameplay, fixed, techn...</td>\n",
       "      <td>[no, man's, sky, has, a, new, update, and, its...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author                                            comment  \\\n",
       "145117  12poulet21  patch notes general gameplay fixed technology ...   \n",
       "\n",
       "       subreddit                               parent_comment  label  \\\n",
       "145117    gaming  no man's sky has a new update and its huge       0   \n",
       "\n",
       "                                            comment_token  \\\n",
       "145117  [patch, notes, general, gameplay, fixed, techn...   \n",
       "\n",
       "                                     parent_comment_token  \n",
       "145117  [no, man's, sky, has, a, new, update, and, its...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.comment_token.map(len) == 1434]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10717208 words total, with a vocabulary size of 168246\n",
      "Max sentence length is 1247\n"
     ]
    }
   ],
   "source": [
    "destroy(145117)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>comment</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>parent_comment</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_token</th>\n",
       "      <th>parent_comment_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>359549</th>\n",
       "      <td>ithinkPOOP</td>\n",
       "      <td>comcast comcast comcast comcast comcast comcas...</td>\n",
       "      <td>funny</td>\n",
       "      <td>10 months later and the swastika is still on t...</td>\n",
       "      <td>0</td>\n",
       "      <td>[comcast, comcast, comcast, comcast, comcast, ...</td>\n",
       "      <td>[10, months, later, and, the, swastika, is, st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author                                            comment  \\\n",
       "359549  ithinkPOOP  comcast comcast comcast comcast comcast comcas...   \n",
       "\n",
       "       subreddit                                     parent_comment  label  \\\n",
       "359549     funny  10 months later and the swastika is still on t...      0   \n",
       "\n",
       "                                            comment_token  \\\n",
       "359549  [comcast, comcast, comcast, comcast, comcast, ...   \n",
       "\n",
       "                                     parent_comment_token  \n",
       "359549  [10, months, later, and, the, swastika, is, st...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.comment_token.map(len) == 1247]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10715961 words total, with a vocabulary size of 168244\n",
      "Max sentence length is 284\n"
     ]
    }
   ],
   "source": [
    "destroy(359549)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10715961 words total, with a vocabulary size of 168244\n",
      "Max sentence length is 284\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "all_words = [word for tokens in data[\"comment_token\"] for word in tokens]\n",
    "sentence_lengths = [len(tokens) for tokens in data[\"comment_token\"]]\n",
    "VOCAB = sorted(list(set(all_words)))\n",
    "print(\"%s words total, with a vocabulary size of %s\" % (len(all_words), len(VOCAB)))\n",
    "print(\"Max sentence length is %s\" % max(sentence_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10)) \n",
    "plt.xlabel('Sentence length')\n",
    "plt.ylabel('Number of sentences')\n",
    "plt.hist(sentence_lengths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24666928 words total, with a vocabulary size of 236138\n",
      "Max sentence length is 4281\n"
     ]
    }
   ],
   "source": [
    "all_words = [word for tokens in data[\"parent_comment_token\"] for word in tokens]\n",
    "sentence_lengths = [len(tokens) for tokens in data[\"parent_comment_token\"]]\n",
    "VOCAB = sorted(list(set(all_words)))\n",
    "print(\"%s words total, with a vocabulary size of %s\" % (len(all_words), len(VOCAB)))\n",
    "print(\"Max sentence length is %s\" % max(sentence_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "955615 words total, with a vocabulary size of 14300\n",
      "Max word length is 21\n"
     ]
    }
   ],
   "source": [
    "all_words = data['subreddit']\n",
    "word_lengths = [len(tokens) for tokens in data[\"subreddit\"]]\n",
    "VOCAB = sorted(list(set(all_words)))\n",
    "print(\"%s words total, with a vocabulary size of %s\" % (len(all_words), len(VOCAB)))\n",
    "print(\"Max word length is %s\" % max(sentence_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[['subreddit','comment','parent_comment']]\n",
    "labels = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>comment</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>politics</td>\n",
       "      <td>nc and nh</td>\n",
       "      <td>yeah i get that argument at this point i'd pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nba</td>\n",
       "      <td>you do know west teams play against west teams...</td>\n",
       "      <td>the blazers and mavericks the wests 5 and 6 se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nfl</td>\n",
       "      <td>they were underdogs earlier today but since gr...</td>\n",
       "      <td>they're favored to win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BlackPeopleTwitter</td>\n",
       "      <td>this meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>deadass don't kill my buzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MaddenUltimateTeam</td>\n",
       "      <td>i could use one of those tools</td>\n",
       "      <td>yep can confirm i saw the tool they use for th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            subreddit                                            comment  \\\n",
       "0            politics                                         nc and nh    \n",
       "1                 nba  you do know west teams play against west teams...   \n",
       "2                 nfl  they were underdogs earlier today but since gr...   \n",
       "3  BlackPeopleTwitter  this meme isn't funny none of the \"new york ni...   \n",
       "4  MaddenUltimateTeam                    i could use one of those tools    \n",
       "\n",
       "                                      parent_comment  \n",
       "0  yeah i get that argument at this point i'd pre...  \n",
       "1  the blazers and mavericks the wests 5 and 6 se...  \n",
       "2                            they're favored to win   \n",
       "3                         deadass don't kill my buzz  \n",
       "4  yep can confirm i saw the tool they use for th...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,GlobalAveragePooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Convolution1D, Flatten, Dropout,MaxPooling1D\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "x_train_text, x_test_text, y_train, y_test = train_test_split(\n",
    "      features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>comment</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>518197</th>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>killer app confirmed!</td>\n",
       "      <td>windows 10 comes with a 3d modeling program!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472026</th>\n",
       "      <td>PS4</td>\n",
       "      <td>yea its called playstationfourpointfive it wil...</td>\n",
       "      <td>is there any new version of ps4 coming?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580389</th>\n",
       "      <td>news</td>\n",
       "      <td>yes our government must take care of us withou...</td>\n",
       "      <td>to play devils advocate here we have no idea w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309623</th>\n",
       "      <td>wow</td>\n",
       "      <td>daily beatings are good for the character</td>\n",
       "      <td>how to help my girlfriend's character? so my g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108839</th>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>aurelion sol with stars?</td>\n",
       "      <td>jax with lamp posts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              subreddit                                            comment  \\\n",
       "518197     pcmasterrace                              killer app confirmed!   \n",
       "472026              PS4  yea its called playstationfourpointfive it wil...   \n",
       "580389             news  yes our government must take care of us withou...   \n",
       "309623              wow         daily beatings are good for the character    \n",
       "108839  leagueoflegends                           aurelion sol with stars?   \n",
       "\n",
       "                                           parent_comment  \n",
       "518197       windows 10 comes with a 3d modeling program!  \n",
       "472026            is there any new version of ps4 coming?  \n",
       "580389  to play devils advocate here we have no idea w...  \n",
       "309623  how to help my girlfriend's character? so my g...  \n",
       "108839                               jax with lamp posts   "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine text for total corpus for tokenizing later\n",
    "data_text = x_train_text + x_test_text\n",
    "\n",
    "comment_top_words = 168000\n",
    "parent_comment_top_words = 236000\n",
    "subreddit_top_words = 14300\n",
    "\n",
    "comment_tokenizer = Tokenizer(num_words= comment_top_words)\n",
    "parent_tokenizer = Tokenizer(num_words = parent_comment_top_words)\n",
    "subreddit_tokenizer = Tokenizer(num_words = subreddit_top_words)\n",
    "\n",
    "comment_tokenizer.fit_on_texts(features['comment'])\n",
    "parent_tokenizer.fit_on_texts(features['parent_comment'])\n",
    "subreddit_tokenizer.fit_on_texts(features['subreddit'])\n",
    "\n",
    "comment_train_tokens = comment_tokenizer.texts_to_sequences(x_train_text['comment'])\n",
    "parent_train_tokens = parent_tokenizer.texts_to_sequences(x_train_text['parent_comment'])\n",
    "subreddit_train_tokens = subreddit_tokenizer.texts_to_sequences(x_train_text['subreddit'])\n",
    "\n",
    "test_comment_train_tokens = comment_tokenizer.texts_to_sequences(x_test_text['comment'])\n",
    "test_parent_train_tokens = parent_tokenizer.texts_to_sequences(x_test_text['parent_comment'])\n",
    "test_subreddit_train_tokens = subreddit_tokenizer.texts_to_sequences(x_test_text['subreddit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vocab = comment_top_words + parent_comment_top_words + subreddit_top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2344, 1167, 540]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_train_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_dict = comment_tokenizer.word_index\n",
    "inv_comment = {v: k for k, v in comment_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "killer app confirmed\n"
     ]
    }
   ],
   "source": [
    "print(inv_comment[2344],inv_comment[1167], inv_comment[540])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[854, 200, 424, 16, 3, 3002, 14201, 1319]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_train_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dict = parent_tokenizer.word_index\n",
    "inv_parent = {v: k for k, v in parent_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windows 10 comes with a 3d modeling program\n"
     ]
    }
   ],
   "source": [
    "print(inv_parent[854],inv_parent[200],inv_parent[424],inv_parent[16],inv_parent[3],inv_parent[3002],inv_parent[14201],inv_parent[1319])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_train_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_dict = subreddit_tokenizer.word_index\n",
    "inv_subreddit = {v: k for k, v in subreddit_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pcmasterrace'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_subreddit[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_count(train, test):\n",
    "    num_tokens = [len(tokens) for tokens in train + test]\n",
    "    return num_tokens\n",
    "\n",
    "def max_tokens(token_list):\n",
    "    return np.mean(token_list) + 2.5 * np.std(token_list)\n",
    "\n",
    "num_comment_token = token_count(comment_train_tokens,test_comment_train_tokens)\n",
    "max_comment_token = max_tokens(num_comment_token)\n",
    "max_comment_token = int(max_comment_token)\n",
    "\n",
    "num_parent_token = token_count(parent_train_tokens,test_parent_train_tokens)\n",
    "max_parent_token = max_tokens(num_parent_token)\n",
    "max_parent_token = int(max_parent_token)\n",
    "\n",
    "max_subreddit_token = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tokens = max_comment_token + max_parent_token + max_subreddit_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "pad = 'pre'\n",
    "\n",
    "comment_train_pad = pad_sequences(comment_train_tokens, maxlen = max_comment_token, padding=pad, truncating=pad)\n",
    "parent_train_pad = pad_sequences(parent_train_tokens, maxlen = max_parent_token, padding=pad, truncating=pad)\n",
    "reddit_train_pad = pad_sequences(subreddit_train_tokens, maxlen = max_subreddit_token, padding=pad, truncating=pad)\n",
    "\n",
    "comment_test_pad = pad_sequences(test_comment_train_tokens, maxlen=max_comment_token, padding=pad, truncating=pad)\n",
    "parent_test_pad = pad_sequences(test_parent_train_tokens, maxlen = max_parent_token, padding=pad, truncating=pad)\n",
    "reddit_test_pad = pad_sequences(test_subreddit_train_tokens, maxlen = max_subreddit_token, padding=pad, truncating=pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(764492, 30)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(764492, 129)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(764492, 21)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.hstack([reddit_train_pad, comment_train_pad, parent_train_pad])\n",
    "test_x = np.hstack([reddit_test_pad, comment_test_pad, parent_test_pad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(764492, 180)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191123, 180)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical  # Makes \"one-hot\" encoding from label\n",
    "\n",
    "y_train_hot = to_categorical(y_train, num_classes=2)\n",
    "y_test_hot = to_categorical(y_test, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_vocab:  418300\n",
      "total_token:  180\n"
     ]
    }
   ],
   "source": [
    "print('total_vocab: ', total_vocab)\n",
    "print('total_token: ', total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   400/764492 [..............................] - ETA: 35:58:21 - loss: 0.7019 - acc: 0.4700"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-152-500f9ad85f25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_hot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim= total_vocab,\n",
    "                    output_dim= 64,\n",
    "                    input_length = total_tokens))\n",
    "\n",
    "model.add(Convolution1D(256, 3, padding='same'))\n",
    "model.add(Convolution1D(128, 3, padding='same'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Convolution1D(64, 3, padding='same'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Convolution1D(32, 3, padding='same'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Convolution1D(16, 3, padding='same'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Convolution1D(8, 3, padding='same'))\n",
    "model.add(Convolution1D(8, 3, padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(180,activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_x, y_train_hot, epochs=10, batch_size = 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on the test set\n",
    "scores = model.evaluate(test_x, y_test_hot, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
